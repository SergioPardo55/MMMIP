{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOoMdNVUG9714gln0SMqG19"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"quAd5kUJXS2h"},"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","from scipy.signal import convolve2d\n","from skimage.io import imread"]},{"cell_type":"code","source":["rootfolder = '.'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4b4erfTUO7kA","executionInfo":{"status":"ok","timestamp":1684791659372,"user_tz":-120,"elapsed":2089,"user":{"displayName":"Diego Carrera","userId":"06552745026585804274"}},"outputId":"004f508f-dc98-41f2-f1cc-4669f6689ce5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"n9KEr7OUZ00l"},"source":["Define the function to compute the kernel given the weights and the degree of the polynomial"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ig2s_rwtZx6P"},"outputs":[],"source":["def compute_2D_LPA_kernel(w, N):\n","    # compute the 2D LPA kernel for a given weights and polynomial degree\n","    # input:\n","    #   w: matrix containing the weights for the local LS problem\n","    #   N: degree of the polynomial approximation\n","    # return:\n","    #   g: the computed LPA kernel\n","\n","    \n","    # window size is the lenght of the weight vector\n","    r, c = w.shape\n","    M = r*c\n","    \n","    # create the matrix T\n","    tx = np.linspace(0, 1, c)\n","    ty = np.linspace(0, 1, r)\n","    tx, ty = np.meshgrid(tx, ty)\n","    tx = tx.reshape(-1)\n","    ty = ty.reshape(-1)\n","    T = np.zeros((M,(N+1)**2))\n","    cnt = 0\n","    for i in range(N+1):\n","        for j in range(N-i+1):\n","            if i==0 and j==0:\n","                T[:, cnt] = np.ones(M)\n","            else:\n","                T[:, cnt] = tx**i * ty**j\n","            cnt = cnt + 1\n","    T = T[:, :cnt]\n","\n","    # unroll the matrix of the weights    \n","#    w =\n","\n","    # generate the inverse of weights\n","#    winv =\n","    \n","    # set to zero weights that are inf\n","#    winv\n","\n","    # define the weight matrix\n","#    W = \n","#    Winv =\n","    \n","    ## construct the LPA kernel\n","    \n","    # comput the qr decomposition of WT\n","#    Q, R = \n","\n","    # define Qtilde\n","#    Qtilde = \n","    \n","    # adjust Qtilde with the weights matrix squared\n","#    W2Qtilde =\n","\n","    # select the central row of W2Qtilde\n","#    row = \n","\n","    # compute the kernel\n","#    g_bar = \n","\n","    #reshape the kernel in a matrix\n","#    g_bar = \n","    \n","    # flipping, since it is used in convolution\n","#    g = \n","\n","    return g\n"]},{"cell_type":"markdown","source":["Load the image and add the noise"],"metadata":{"id":"gcNKF8y9O46G"}},{"cell_type":"code","source":["img = imread(f'{rootfolder}/data/cameraman.png') / 255\n","\n","sigma_noise = 20/255\n","noisy_img = img + np.random.normal(size=img.shape) * sigma_noise\n","\n","#psnr_noisy = \n"],"metadata":{"id":"pp5KWkxlO6lQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n","ax[0].imshow(img, cmap='gray')\n","ax[0].set_title('Original image')\n","\n","ax[1].imshow(noisy_img, cmap='gray')\n","ax[1].set_title(f'Noisy image, PSNR = {psnr_noisy:.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsxElZddPSs9","outputId":"1c7e7691-34e6-465b-f5de-acbc6ae5719e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'Noisy image, PSNR = 22.10')"]},"metadata":{},"execution_count":147}]},{"cell_type":"markdown","source":["LPA-ICI 2D\n","----------\n","Set the LPA-ICI parameters"],"metadata":{"id":"34S3SYMckqtD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yYPg7PvuaT9Y"},"outputs":[],"source":["# maximum degree of polynomial used for fitting\n","N = 1\n","\n","# parameter for the confidence intervals in the ICI rule\n","Gamma = 2\n","\n","# Set all the scale values\n","hmax = 21\n","all_h = np.arange(1, hmax+1)"]},{"cell_type":"markdown","metadata":{"id":"DMZBeqQtcunJ"},"source":["Generate the LPA kernels for all the scale. Use centered weights.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qUUogpW_qmdi"},"outputs":[],"source":["all_g = []\n","for i, h in enumerate(all_h):\n","        # define the weights for the scale h symmetric\n","\n","        # size of the weight MATRIX\n","#        w = \n","\n","        # compute and store the kernel g\n","        g = compute_2D_LPA_kernel(w, N)\n","        all_g.append(g)"]},{"cell_type":"markdown","metadata":{"id":"fBP6KA27s_kF"},"source":["Initialize all the variables for the ICI rule"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23d65QPcrRso"},"outputs":[],"source":["# initialize the estimate for each scale\n","yhat = np.zeros((img.shape))\n","\n","# initialize the vector containing the best scale for each sample\n","best_scale = np.zeros(shape=yhat.shape)\n","\n","# initialize the lower and upper bound matrices\n","lower_bounds = - np.inf * np.ones(shape=yhat.shape)\n","upper_bounds = np.inf * np.ones(shape=yhat.shape) "]},{"cell_type":"markdown","source":["Loop over all the scales"],"metadata":{"id":"AaCGFuCrlbGI"}},{"cell_type":"code","source":["for i, h in enumerate(all_h):\n","    g = all_g[i]\n","\n","    # compute the estimate for the scale h\n","#    yhat_h = \n","\n","    # compute the lower and upper bound of the confidence interval for the scale h\n","#    lb =\n","#    ub =\n","\n","    # update the lower and upper bounds\n","#    lower_bounds =\n","#    upper_bounds =\n","\n","    # identify for which samples h is the best scale according to the\n","    # ICI rule and update the best_scale vector accordingly\n","    # update best_scale\n","\n","    # update the estimate\n","    # update yhat"],"metadata":{"id":"5nuG5GihlgQ3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dVx-E5q8tCs3"},"source":["Compute the PSNR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHi9A8uXqryE"},"outputs":[],"source":["# psnr = "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tBJUSUuqdp7v"},"outputs":[],"source":["fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n","ax[0].imshow(yhat, cmap='gray')\n","ax[0].set_title(f'LPA-ICI estimate, PSNR = {psnr:.2f}')\n","\n","ax[1].imshow(best_scale)\n","ax[1].set_title('Best scale for each pixel')\n","fig.colorbar(ax[1].pcolormesh(best_scale), ax=ax[1])"]},{"cell_type":"markdown","source":["Anisotropic LPA-ICI\n","------------------------\n","Set the parameters\n"],"metadata":{"id":"kMvwf8ram7Lf"}},{"cell_type":"code","source":["# maximum degree of polynomial used for fitting\n","N = 1\n","\n","# parameter for the confidence intervals in the ICI rule\n","Gamma = 2\n","\n","# Set all the scale values\n","hmax = 21\n","all_h = np.arange(1, hmax+1)\n","\n","# set all the direction values\n","all_theta = np.arange(4)"],"metadata":{"id":"ZtsjdjSWnENQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Generate the LPA kernels for all the scales and all the directions"],"metadata":{"id":"tfg3XYvInP9p"}},{"cell_type":"code","source":["all_g = []\n","\n","for theta in all_theta:\n","\n","    all_g_theta = []\n","    for i, h in enumerate(all_h):\n","        # define the weights for the scale h and the direction theta\n","#        if theta \n","#            w = \n","\n","        # compute and store the kernel g\n","        g = compute_2D_LPA_kernel(w, N)\n","\n","        all_g_theta.append(g)\n","\n","    all_g.append(all_g_theta)\n"],"metadata":{"id":"oy5unf_onSWi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialize all the variables "],"metadata":{"id":"OPapyBO_oFEj"}},{"cell_type":"code","source":["# initialize the estimate for each scale\n","yhat = np.zeros(img.shape)\n","\n","# initialize the matrix of the aggregation weights\n","weights = np.zeros(img.shape)\n"],"metadata":{"id":"pNrjeHXOoRbo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use the LPA-ICI to compute find the best scale for each direction and compute the finale estimates"],"metadata":{"id":"r46En2rOWKtF"}},{"cell_type":"code","source":["# loop over all the directions\n","for theta in all_theta:\n","    # initialize the estimate for the direction theta\n","    yhat_theta = np.zeros(img.shape) \n","    \n","    # initialize the matrix all the variances for the direction theta\n","    var_theta = np.zeros(img.shape) \n","\n","    # initialize the lower and upper bounds matrices\n","    # lower_bounds =\n","    # upper_bounds =\n","\n","    # loop over all scales\n","    all_g_theta = all_g[theta]\n","    for i, h in enumerate(all_h):\n","        g = all_g_theta[i]\n","\n","        # compute the estimate for the scale h\n","#        yhat_h = \n","\n","        # compute the lower and upper bound of the confidence interval for the scale h\n","#        lb = \n","#        ub =\n","\n","        # update the lower and upper bounds\n","#        lower_bounds = \n","#        upper_bounds = \n","\n","        # update the estimate\n","        # update yhat_theta\n","\n","        # update the matrix with the variances\n","        # update var_theta\n","      \n","    # update the estimates and the weights\n","    # yhat = \n","    # weights = \n","\n","# compute the final estimates\n","yhat = yhat / weights"],"metadata":{"id":"qdOODckDWJVn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compute the PSNR"],"metadata":{"id":"_6fDHh9FYHk9"}},{"cell_type":"code","source":["# psnr ="],"metadata":{"id":"xvJft9nYYJQo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,10))\n","plt.imshow(yhat, cmap='gray')\n","plt.title(f'LPA-ICI estimate, PSNR = {psnr:.2f}')\n"],"metadata":{"id":"bioSFH9dYHPB"},"execution_count":null,"outputs":[]}]}